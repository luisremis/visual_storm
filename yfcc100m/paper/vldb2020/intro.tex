\section{Introduction}
\label{intro}

Visual computing workloads performing analytics on
video or image data, either off-line or streaming,
have become prolific across a wide range of application domains.
This is in part due to the growing ability of machine learning techniques to
extract information out of the visual data which can subsequently be used
for informed decision making \cite{vdms-nips}.
The insights this information can provide depend on the
application: a retail vendor might be interested in the amount of time
shoppers spend in front of a specific product, while a medical expert might
want to see the effect of a specific treatment on the size of a tumor.

There are many applications that can be studied through the use of large
and public available datasets. But before getting started, there is usually
a large effort devoted to cleaning up the data. For this work, we use
the YFCC100m dataset as an example given that we have use the same dataset
for multiple proof of concepts and applications without our research lab.
Applications include basic image search functionality (through the use
of human-generated tags), advanced image search through the use of
machine generated tags for each image, and video summarization.
In all cases, it was needed to select a subset of the data before running
any processing. Selecting subsets of data is by itself a time consuming task,
as it involves loading all metadata into a solution that enables searched
based on tags (relational database, graph database, csv files, etc), and
building the necessary pipelines for querying and retrieving the right data.

Despite this rich and varied usage environment, there has been very little
research on the management of visual data.
Most of the current storage solutions are
an ad-hoc collection of tools combined with custom scripts to tie them
together, unique not only to a specific discipline but often to individual
researchers. For example, consider an ML developer constructing a pipeline
for extracting brain tumor information from existing brain images in a
classic medical imaging use case. This requires assigning consistent
identifiers for the scans and adding their metadata in
some form of relational or key-value database. If the queries require
search over some patient information, then patients have to be associated
with their brain scans. Finally, if the ML pipeline needs images that
are of a size different than the stored ones, there is additional compute
diverted towards preprocessing after the potentially larger images are
fetched. All these steps require investigation of different software
solutions that provide various functionalities that can then be stitched
together with a script for this specific use case.
Moreover, if the pipeline identifies
new metadata to be added for the tumor images, most databases make it
hard to evolve the schema on the fly.
Not only do these ad hoc solutions make replicating experiments
difficult, they do not scale well to real-world applications.
Addressing the storage and retrieval of visual data necessitates a complete
overhaul of the storage architecture,
preferably using emerging breakthroughs in
heterogeneous memory and storage for efficiency.

Data scientist and machine learning developers usually end up building ad-hoc
solutions through a combination of databases and file systems to store metadata
and visual data (images, videos), respectively.

In this paper, we also expand on the Video and Feature Vector capabilities of
VDMS, which are part of the latest additions to the system.
We analyze different functionalities and trade-offs for this type of data,
in combination with metadata filtering. To the best of our knowledge, this
set of functionalities are unique to VDMS and we were not able to find a system
with similar functionality.

We show how VDMS can be used as the single and centralize point for data
management and data access even when having multiple modalities of data:
Metadata, Image, Videos, and Feature Vectors, all part of a comprehensive
dataset that is used for multiple use-cases.

\begin{comment}

We present the Visual Data Management System (VDMS)\cite{darkside},
an Open Source project designed to enable efficient access of visual data.
Since visual data often contains
rich metadata (such as objects, locations, and time), VDMS stores this
information in a high performance graph database. Using this metadata, VDMS
can quickly identify which data is relevant to a given query.
Additionally, VDMS uses a custom library to store and retrieve visual data,
which provides an interface for machine friendly formats as well as
traditional formats. These new formats are designed to support applications
that are often interested in specific areas of images or videos,
particularly when the individual object is large.

\end{comment}
