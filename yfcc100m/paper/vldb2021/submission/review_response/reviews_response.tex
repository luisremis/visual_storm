\documentclass[11pt]{proposalnsf}
\usepackage{times}
\usepackage{mathptmx}
\usepackage{epsfig}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{pdfpages}
\usepackage{url}
\usepackage{listings}
\usepackage{array}
\usepackage[noend,nofillcomment]{algorithm2e}
\usepackage{verbatim}
%\usepackage{algorithmic}
%\usepackage{amsfonts}
%\usepackage{lineno}
\usepackage{ifthen}
\usepackage{booktabs}

\usepackage{color}

\usepackage{multirow}
\usepackage{balance}  % for  \balance command ON LAST PAGE  (only there!)

\makeatletter
\def\tightitemize{\ifnum \@itemdepth >3 \@toodeep\else \advance\@itemdepth \@ne
\edef\@itemitem{labelitem\romannumeral\the\@itemdepth}%
\list{\csname\@itemitem\endcsname}{\setlength{\topsep}{-\parskip}\setlength{\parsep}{0in}\setlength{\itemsep}{0in}\setlength{\parskip}{0in}\def\makelabel##1{\hss\llap{##1}}}\fi}
\let\endtightitemize =\endlist
\def\tightenumerate{%
\ifnum \@enumdepth >\thr@@\@toodeep\else
\advance\@enumdepth\@ne
\edef\@enumctr{enum\romannumeral\the\@enumdepth}%
\expandafter
\list
\csname label\@enumctr\endcsname
{\setlength{\topsep}{-\parskip}\setlength{\parsep}{0in}\setlength{\itemsep}{0in}\setlength{\parskip}{0in}\usecounter\@enumctr\def\makelabel##1{\hss\llap{##1}}}%
\fi}
\let\endtightenumerate =\endlist
\makeatother
\renewcommand{\refname}{\centerline{References cited}}

% this handles hanging indents for publications
\def\rrr#1\\{\par
\medskip\hbox{\vbox{\parindent=2em\hsize=6.12in
\hangindent=4em\hangafter=1#1}}}

\def\baselinestretch{1}

\begin{document}

\begin{center}
{\Large{\bf VLDB 2021 - Response to Reviews: \\
Using VDMS to Index and Search 100M Images}}

\end{center}

%===========================================================
\section{General Description of Changes}
%===========================================================

The authors would like to thank the program committee and the reviewers
for the comments and suggestions,
instrumental to increase the quality of our work and its presentation.

We have addressed comments from every reviewer separately, but the following
list summarize the main updates:

\begin{itemize}
  \item We have added and run a new experiment that compares VDMS and baseline
        for queries that do not run a pre-processing operations, following
        reviewer's suggestions.
        We expand the analysis of the results including these findings.
  \item We have expanded on the type of supported pre-processing
        operations, and more details on VDMS API design in general.
  \item We have expanded on the description of the ACID properties offered
        by VDMS and how that mechanism work.
  \item We have expanded on the type of queries supported by VDMS,
        including similarity-search based on feature vectors,
        which is a feature currently supported by the system.
  \item We have added a "Future Work" sections where we describe some
        of the limitations found during this experiments, as well as the
        near and long term line of work after this paper.
\end{itemize}

%===========================================================
\section{Reviewer \#1}
%===========================================================

\noindent %
\textbf{
D1 (W1): Although VDMS mentions that it supports Visual Feature Vectors as
first class citizens in Section 3.3, the queries used in evaluation
do not include an example.
}\bigskip

Thanks for your comment.
Following feedback and suggestions from last year submission at this same venue,
we decided to skip the feature vector functionality evaluation and
focus on image search based on metadata to better be able to compare
against well-known baselines.
We should note that similarity search based on feature vectors
is fully implemented, and you can find the more details on the project's wiki
\footnote{https://github.com/IntelLabs/vdms/wiki/Descriptors-Tutorial}
\footnote{https://github.com/IntelLabs/vdms/wiki/FindDescriptor}.

Including an analysis of similarity search in this same work would also
complicate the implementation of the baseline, making it harder to understand
and isolate the main sources of performance gains.
We have a preliminary implementation of baselines for our internal use cases,
and it meant combining more than 4 systems (SQL database, web server, client side
pre-processing with OpenCV, some quick-and-dirty implementation
to provide client-server architecture to Faiss/Annoy, given that these
are just C++ libraries).
This increases the complexity of the baseline systems, adding
more parameters to tune, and complicating the understanding of the results.
We have decided to focus this work on image search based on metadata tags
and the addition of needed pre-processing operations, and
work on a similarity-search specific evaluation as a next step.
If reviewers are interested in learning more about our similarity search functionality,
we have attached as an appendix part of the evaluation we submitted last year.
It also includes initial evaluation on the Video API, which works in a very
similar way as it does for images.
We will continue to improve this evaluation, and submit to arxiv directly
as an extension of this work.

\bigskip
\noindent %
\textbf{
D2 (W1): All queries involve “resize” operation, which is expensive for the
baselines since it is happening on the client side.
A simplistic query without resizing can show how the graph model performs
against traditional RDS DBs (i.e., will show that VDMS has comparable
performance even for such use-case without "visual manipulation").
}\bigskip

This is a great point, we very much appreciate the suggestion.
We have run a new experiment and added a new figure to the paper (Figure 9),
where we compare 3 of the queries with and without the resize operation
to understand the difference in performance better.
We have also added an explanation on these differences in performance
in the final version, and made these results publicly available
\footnote{https://github.com/luisremis/visual\_storm/tree/master/yfcc100m/python/eval/results/resize\_comparison}
(as the rest of the evaluation in this work).
Note that, even if the resize happens on the client side in the case of both
baselines we have built, the computing capabilities of the server and the
client are identical.
This is on purpose, to avoid the difference in computing power for the
resize operation to affect the understanding of the results.

\bigskip
\noindent %
\textbf{
D3 (W2): It is not clear which queries are supported or not.
The queries used for evaluation are based on tags and geo search.
What about visual-based queries? For example, is image similarity search based
on Visual Feature Vectors within a geographical region supported?
}\bigskip

VDMS does support the suggested query, i.e., perform a similarity search based
on feature vectors and also filter by geographical location.
This can be achieved using the very similar queries as the one used in
the present evaluation, plus the use of the feature vector queries,
that are natively supported using the same set of APIs (as we mention in D1).
Because of space constraints, we were not able to accommodate initial evaluation
we have been working on for Feature Vector-based search specifically,
and we plan to perform a more comprehensive evaluation on this functionality
of this feature because of its relevance when processing visual data, as well
as our own needs in our use cases.

\bigskip
\noindent %
\textbf{
D4 (W2): Section 4.3.1, paragraph 5, mentions that INTERSECTION operation is not
yet implemented at the server side.
A discussion on current limitations/future work for such queries or queries
such as in D3, will be better to be clarified in paper.
}\bigskip

Thanks for this comment, great suggestion.
We have added a "Future Work" section where we cover this and D3,
expanding further on the most immediate lines of improvement and
research for the VDMS project.

\bigskip
\noindent %
\textbf{
D5 (W3): Section 4.2 paragraph 1, desing
}\bigskip

Fixed in final version.

\bigskip

%===========================================================
\newpage
\section{Reviewer \#4}
%===========================================================

\noindent %
\textbf{
D1. The proposed solution seems to use the functionalities of the existing systems
as it is. Authors should provide more original ideas or more innovative designs.
For example, providing optimizations that specifically target visual data or query
patterns associated could have been more meaningful to the research communities and
convince users to replace their customized solution to VDMS.
}\bigskip

Thanks for your comment, these are important clarifications to add.
We have expanded on additional details on which operations we support and our
decision for choosing the operations in Section 3, and how supporting
these operations natively opens optimization possibilities that we exploit.
We also elaborated more on the benefits of
using VDMS over ad-hoc solutions in Section 3.1.
We avoided expanding on supported operations for images due to space constraints,
and because these are fully documented on the project's wiki
\footnote{https://github.com/IntelLabs/vdms/wiki}.
The wiki also contains the full documentation on APIs for video and similarity
search, among other things, which work together with the API we used for
image search for this work, providing a unified API for all the data applications need.

\bigskip
\noindent %
\textbf{
D2. Both baselines are similar in architecture, and the evaluation has not effectively
highlighted the performance gain of other design choices authors made in VDMS,
except that the VDMS server process both metadata operation and image operation
within only one round of communication with clients.
For example, benchmarking systems can be built to test in isolation the
improvement on metadata handling.
}\bigskip

Thank you for the input.
To demonstrate the benefits of VDMS more clearly, we have added Figure 9,
which compares queries with and without the resize operation.
Without the resize operation, the evaluation shows the
improvement on metadata handling better, plus the effect of a single round
of communication between client and the server (as it is the case with VDMS).
Because we design VDMS for visual data as the first class elements,
we focused our evaluation on the retrieval of visual objects rather
than metadata only.
When it comes to building solutions that primarily depend on metadata,
rather than actual visual objects, the authors believe that VDMS is not
the right solution, given that there are many other commercially available
solutions (relational databases, graph databases, document-oriented databases, etc)
that have been optimized over many decades and provide a level of
functionality and maturity that is sufficient for the majority of the use cases.

\bigskip
\noindent %
\textbf{
D3. The paper should detail the types of queries, and image preprocessing it supports,
as this being “one of the most differentiating aspects” as mentioned by them.
And for the selection of operations supported, authors need to argue for their
decision in the application contexts.
}\bigskip

Thank you for this recommendation, it is an important clarification we have added.
In a nutshell, we add pre-processing operations to VDMS API only if such
operations are application-independent.
Operations like resize, crop, zoom, trans-coding, convert to black and white,
re-sample video, and access to random frames in a video, among others, are
example of operations that are needed in many different applications,
and that it is performed in the same way in all uses.
We have provided additional details on which operations we support and our
decision for choosing the operations in Section 3.

\bigskip
\noindent %
\textbf{
D4. Data scientists commonly perform data exploration on raw data and interactively
curate their datasets for downstream tasks like model training.
VDMS could design new mechanisms to support interactive analysis,
which would be beneficial.
}\bigskip

This is a great point, and a primary motivation for building a system like VDMS.
VDMS, by design, supports functionality that makes it easy to build
iterative analysis using its API.
To support interactive analysis, a front-end could be implemented on top of
VDMS API as a web app without needing any additional abstractions.
An example of such front-end can be found here:
\url{http://coco.datasets.aperturedata.io}.
This front-end is very thin, as most of the heavy-load is done by VDMS through
the interfaces described in this work
(plus a thin REST abstraction we have added recently).
In section 3 of final version, we have added a brief mention to this mechanism.

\bigskip
\noindent %
\textbf{
D5. In terms of scalability, the paper only shows that VDMS can handle large
datasets, yet it is not known how VDMS can scale horizontally with more
computation resources.
For more complex logic of image preprocessing, VDMS will suffer from its
single server capacity.
}\bigskip

Thanks for this comment.
We have included this capability in the "Future Work" section
added to the final version.
We are currently working on a distributed version of the system.

%===========================================================
\newpage
\section{Reviewer \#5}
%===========================================================

\noindent %
\textbf{
D1: VDMS is a valuable contribution to Database systems where it takes
some first important steps to handle visual data as a first-class citizen
instead of considering it a blob of information. However, the description
of VDMS is rather short (only 4 pages), and some critical technical
details are missing. In particular, what are the technical challenges
for supporting ACID properties using the graph model abstraction? Are
the solutions analogous to RDBMS’s? Does VDMS also support crash
recovery like an RDBMS? What are the key challenges for implementing
the new visual object computations?
}\bigskip

Thank you for the comment.
VDMS does support crash recovery through the use of the ACID properties
of the Graph Engine (PMGD).
The design and implementation of PMGD, and the mechanism by which ACID properties
are guaranteed, are currently under submission, and will be published separately.
In Section 3.2, we have added a clarification regarding this detail.

\bigskip
\noindent %
\textbf{
D2: The coverage of persistent memory is underwhelming because persistent memory
is never used in the experiments.
What is the key advantage of using persistent memory and how is it
more suitable for visual data? Why not add experiments comparing VDMS with
and without using PMGD?
}\bigskip

We did not elaborate on advantages of using persistent memory or include
any PMGD experiments primarily due to space constraints, and to avoid
complicating the understand of the experimental evaluation.
In our evaluation, we use SSDs (and not persistent memory) to avoid
being unfair with the baseline systems (which do not have explicit support for
persistent memory abstractions), and have a better understanding of
the results.
PMGD performance evaluation will be published separately to highlight
the advantages of using persistent memory in general.

\bigskip
\noindent %
\textbf{
D3: The experiments section seems unnecessarily long, yet missing some important
details. All the experiments are performed on images and do not handle videos or feature
values at all. For example, video operations may include interval operations or video
clip retrieval. Some parts seem redundant, e.g., the description of Figure 9 seems
near-identical to that of Figure 8.
}\bigskip

Thank you for this comment, and it is a great suggestion.
Figure 8 and 9 are quite similar but provide the performance difference with different
number of concurrent clients we found interesting to be shared.
We have removed figure 9 and replaced it with a figure
demonstrating the difference between queries with and without the resize operation.

The paper is focused on an image search application so we did not include any
experiments on videos or feature vectors, but we have attached as an appendix
part of our preliminary evaluation using similarity search.
It also includes initial evaluation on the Video API, which works in a very
similar way as it does for images.

\bigskip
\noindent %
\textbf{
D4: There are some minor typos.\\
Page 1: “need for multiple system” $\rightarrow$  “need for multiple systems”\\
Page 5: “desing specifically” $\rightarrow$ “designed specifically”\\
Page 7: “images, taglist, and taglist” $\rightarrow$ “images, taglist, and autotags”\\
Page 10, Figure 6: “10M database).” $\rightarrow$ “10M database”
}\bigskip

Thank you for highlighting this. All typos are fixed in the final version.

\pagenumbering{arabic}

\end{document}
