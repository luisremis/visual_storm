\documentclass[11pt]{proposalnsf}
\usepackage{times}
\usepackage{mathptmx}
\usepackage{epsfig}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{pdfpages}
\usepackage{url}
\usepackage{listings}
\usepackage{array}
\usepackage[noend,nofillcomment]{algorithm2e}
\usepackage{verbatim}
%\usepackage{algorithmic}
%\usepackage{amsfonts}
%\usepackage{lineno}
\usepackage{ifthen}
\usepackage{booktabs}

\usepackage{color}

\usepackage{multirow}
\usepackage{balance}  % for  \balance command ON LAST PAGE  (only there!)

\makeatletter
\def\tightitemize{\ifnum \@itemdepth >3 \@toodeep\else \advance\@itemdepth \@ne
\edef\@itemitem{labelitem\romannumeral\the\@itemdepth}%
\list{\csname\@itemitem\endcsname}{\setlength{\topsep}{-\parskip}\setlength{\parsep}{0in}\setlength{\itemsep}{0in}\setlength{\parskip}{0in}\def\makelabel##1{\hss\llap{##1}}}\fi}
\let\endtightitemize =\endlist
\def\tightenumerate{%
\ifnum \@enumdepth >\thr@@\@toodeep\else
\advance\@enumdepth\@ne
\edef\@enumctr{enum\romannumeral\the\@enumdepth}%
\expandafter
\list
\csname label\@enumctr\endcsname
{\setlength{\topsep}{-\parskip}\setlength{\parsep}{0in}\setlength{\itemsep}{0in}\setlength{\parskip}{0in}\usecounter\@enumctr\def\makelabel##1{\hss\llap{##1}}}%
\fi}
\let\endtightenumerate =\endlist
\makeatother
\renewcommand{\refname}{\centerline{References cited}}

% this handles hanging indents for publications
\def\rrr#1\\{\par
\medskip\hbox{\vbox{\parindent=2em\hsize=6.12in
\hangindent=4em\hangafter=1#1}}}

\def\baselinestretch{1}

\begin{document}

\begin{center}
{\Large{\bf VLDB 2021 - Response to Reviews: \\
Using VDMS to Index and Search 100M Images}}

\end{center}

%===========================================================
\newpage
\section{Reviewer \#1}
%===========================================================

\noindent %
\textbf{
D1 (W1): Although VDMS mentions that it supports Visual Feature Vectors as
first class citizens in Section 3.3, the queries used in evaluation
do not include an example.
}\bigskip

Thanks for your comment.
We have decided to avoid going in detail on the Feature Vector support
and interfaces primarily due to space constraints.
We should note that this functionality is fully implemented,
and you can find the more details on the project's wiki
\footnote{https://github.com/IntelLabs/vdms/wiki/Descriptors-Tutorial}
\footnote{https://github.com/IntelLabs/vdms/wiki/FindDescriptor}.
Based on feedback from last year submission at this same venue, we decided
to skip the feature vector functionality evaluation and focus on image search
based on metadata to better be able to compare against well-known baselines.
Including an analysis of similarity search in this same work would also
complicate the implementation of the baseline, making it harder to understand
and isolate the main sources of performance gains.
Implementing a baseline that also includes similarity search, even if doable,
would mean combining more than 4 systems (SQL database, web server, client side
pre-processing with OpenCV, some quick-and-dirty implementation
to provide client-server architecture to Faiss/Annoy, given that these
are just C++ libraries).
This would increase the complexity of the baseline systems, adding
more parameters to tune, and complicating the understanding of the results.
We have decided to focus this work on image search based on metadata tags
and the addition of needed pre-processing operations, and
work on a similarity-search specific evaluation as a next step.
If reviewers are interested in learning more about our similarity search functionality,
we have attached as an appendix part of the evaluation we submitted last year.
It also includes initial evaluation on the Video API, which works in a very
similar way as it does for images.
We will continue to improve this evaluation, and submit to arxiv directly
as an extension of this work.

\bigskip
\noindent %
\textbf{
D2 (W1): All queries involve “resize” operation, which is expensive for the
baselines since it is happening on the client side.
A simplistic query without resizing can show how the graph model performs
against traditional RDS DBs (i.e., will show that VDMS has comparable
performance even for such use-case without "visual manipulation").
}\bigskip

This is a great point, we very much appreciate the suggestion.
We have run a new experiment and added a new figure to the paper (Figure 9),
where we compare 3 of the queries with and without the resize operation
to understand the difference in performance better.
We have also added an explanation on these differences in performance
in the final version.
Note that, even if the resize happens on the client side in the case of both
baselines we have built, the computing capabilities of the server and the
client are identical.
This is on purpose, to avoid the difference in computing power for the
resize operation to affect the understanding of the results.


\bigskip
\noindent %
\textbf{
D3 (W2): It is not clear which queries are supported or not.
The queries used for evaluation are based on tags and geo search.
What about visual-based queries? For example, is image similarity search based
on Visual Feature Vectors within a geographical region supported?
}\bigskip

VDMS does support the suggested query, i.e., perform a similarity search based
on feature vectors and also filter by geographical location.
This can be achieved using the very similar queries as the one used in
the present evaluation, plus the use of the feature vector queries,
that are natively supported using the same set of APIs (as we mention in D1).
Because of space constraints, we were not able to accommodate initial evaluation
we have been working on with Feature Vector search specifically,
and we plan to perform a more comprehensive evaluation on this functionality
of this feature because of its relevance when processing visual data, as well
as our own needs in our use cases.

\bigskip
\noindent %
\textbf{
D4 (W2): Section 4.3.1, paragraph 5, mentions that INTERSECTION operation is not
yet implemented at the server side.
A discussion on current limitations/future work for such queries or queries
such as in D3, will be better to be clarified in paper.
}\bigskip

Thanks for this comment, great suggestion.
We have added a "Future Work" section where we cover this and D3,
expanding further on the most immediate lines of improvement and
research for the VDMS project.

\bigskip
\noindent %
\textbf{
D5 (W3): Section 4.2 paragraph 1, desing
}\bigskip

Fixed in final version.

\bigskip

%===========================================================
\newpage
\section{Reviewer \#4}
%===========================================================

\noindent %
\textbf{
D1. The proposed solution seems to use the functionalities of the existing systems
as it is. Authors should provide more original ideas or more innovative designs.
For example, providing optimizations that specifically target visual data or query
patterns associated could have been more meaningful to the research communities and
convince users to replace their customized solution to VDMS.
}\bigskip


Thanks for your comment, these are important clarifications to add.
We have expanded on additional details on which operations we support and our
decision for choosing the operations in Section 3.
We also elaborated more on the benefits of
using VDMS over relational databases in Section 3.1.
We avoided expanding on supported operations for images due to space constraints,
and because these are fully documented on the project's wiki
\footnote{https://github.com/IntelLabs/vdms/wiki}.
The wiki also contains the full documentation on APIs for video and similarity
search, among other things, which work together with the API we used for
image search for this work, providing a unified API for all the data applications need.

\bigskip
\noindent %
\textbf{
D2. Both baselines are similar in architecture, and the evaluation has not effectively
highlighted the performance gain of other design choices authors made in VDMS,
except that the VDMS server process both metadata operation and image operation
within only one round of communication with clients.
For example, benchmarking systems can be built to test in isolation the
improvement on metadata handling.
}\bigskip

Thank you for the input.
To demonstrate the benefits of VDMS more clearly, and to address another
reviewers' comment,  we have added Figure 9, which compares queries
with and without the resize operation.
Without the resize operation, the evaluation shows the
improvement on metadata handling better, plus the effect of a single round
of communication between client and the server (as it is the case with VDMS).

\bigskip
\noindent %
\textbf{
D3. The paper should detail the types of queries, and image preprocessing it supports,
as this being “one of the most differentiating aspects” as mentioned by them.
And for the selection of operations supported, authors need to argue for their
decision in the application contexts.
}\bigskip

Thank you for this recommendation, it is an important clarification we have added.
In a nutshell, we only add pre-processing operations to VDMS API only if such
operation are not application-dependent.
Operations like resize, crop, zoom, transcoding, convert to black and white,
re-sample video, and access to random frames in a video, among others, are
example of operations that are needed in many different applications,
and that it is performed in the same way in all uses.
We have provided additional details on which operations we support and our
decision for choosing the operations in Section 3.

\bigskip
\noindent %
\textbf{
D4. Data scientists commonly perform data exploration on raw data and interactively
curate their datasets for downstream tasks like model training.
VDMS could design new mechanisms to support interactive analysis,
which would be beneficial.
}\bigskip

Interactive analysis of visual data is out of scope for this paper
but this can easily be done using the current implementation of VDMS.
To support interactive analysis, a front-end could be implemented on top of
VDMS API as a web app without needing any additional abstractions.
An example of such front-end can be found here: \url{http://coco.datasets.aperturedata.io}.
This front-end is very thin, as most of the heavy-load is done by VDMS through
the interfaces described in this work
(plus a thin REST abstraction we have added recently).
In section 3 of final version, we have added a brief mention to this mechanism.

\bigskip
\noindent %
\textbf{
D5. In terms of scalability, the paper only shows that VDMS can handle large
datasets, yet it is not known how VDMS can scale horizontally with more
computation resources.
For more complex logic of image preprocessing, VDMS will suffer from its
single server capacity.
}\bigskip

Thanks for this comment.
We have included this capability in the "Future Work" section
added to the final version.
We are currently working on a distributed version of the system.

%===========================================================
\newpage
\section{Reviewer \#5}
%===========================================================

\noindent %
\textbf{
D1: VDMS is a valuable contribution to Database systems where it takes
some first important steps to handle visual data as a first-class citizen
instead of considering it a blob of information. However, the description
of VDMS is rather short (only 4 pages), and some critical technical
details are missing. In particular, what are the technical challenges
for supporting ACID properties using the graph model abstraction? Are
the solutions analogous to RDBMS’s? Does VDMS also support crash
recovery like an RDBMS? What are the key challenges for implementing
the new visual object computations?
}\bigskip

Thank you for the comment.
VDMS does support crash recovery through the use of the ACID properties
of the Graph Engine (PMGD).
The design and implementation of PMGD, and the mechanism by which ACID properties
are guaranteed, are currently under submission, and will be published separately.
In Section 3.2, we have added a clarification regarding this detail.

\bigskip
\noindent %
\textbf{
D2: The coverage of persistent memory is underwhelming because persistent memory
is never used in the experiments.
What is the key advantage of using persistent memory and how is it
more suitable for visual data? Why not add experiments comparing VDMS with
and without using PMGD?
}\bigskip

We did not elaborate on advantages of using persistent memory or include
any PMGD experiments due to page limitations and the use of SSDs
instead of persistent memory in the evaluation.
In our evaluation, we use SSDs (and not persistent memory) to avoid
being unfair with the baseline systems, and have a better understanding of
the results.
PMGD performance evaluation will be published separately to highlight
the advantages of using persistent memory for visual data.

\bigskip
\noindent %
\textbf{
D3: The experiments section seems unnecessarily long, yet missing some important
details. All the experiments are performed on images and do not handle videos or feature
values at all. For example, video operations may include interval operations or video
clip retrieval. Some parts seem redundant, e.g., the description of Figure 9 seems
near-identical to that of Figure 8.
}\bigskip

Thank you for this comment, and it is a great suggestion.
Figure 8 and 9 are quite similar but provide the performance difference with different
number of concurrent clients we found interesting to be shared.
We have removed figure 9 and replaced with a figure
demonstrating the difference between queries with and without the resize operation.

The paper is focused on an image search application so we did not include any
experiments on videos or feature vectors, but we have attached as an appendix
part of the evaluation we submitted last year.
It also includes initial evaluation on the Video API, which works in a very
similar way as it does for images.

\bigskip
\noindent %
\textbf{
D4: There are some minor typos.\\
Page 1: “need for multiple system” $\rightarrow$  “need for multiple systems”\\
Page 5: “desing specifically” $\rightarrow$ “designed specifically”\\
Page 7: “images, taglist, and taglist” $\rightarrow$ “images, taglist, and autotags”\\
Page 10, Figure 6: “10M database).” $\rightarrow$ “10M database”
}\bigskip

Thank you for highlighting this. All typos are fixed in the final version.

\pagenumbering{arabic}

\end{document}
